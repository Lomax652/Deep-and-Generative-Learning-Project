# -*- coding: utf-8 -*-
"""Dsci498-final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WIyLbcibF7AJmioGtIZfonFQX82Lf1sn
"""

from google.colab import files
import os
from PIL import Image

upload_path = "dcgan_dataset/anime"
os.makedirs(upload_path, exist_ok=True)

uploaded = files.upload()
for name in uploaded.keys():
    img = Image.open(name).convert("RGB")
    img = img.resize((64, 64))
    img.save(os.path.join(upload_path, name))

print("âœ… allpicture dcgan_dataset/anime/")

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader

# ------------------------- Config -------------------------
data_path = 'dcgan_dataset'
image_size = 64
batch_size = 128
latent_dim = 100
num_epochs = 600
lr = 0.0002
beta1 = 0.5
real_label = 0.9
fake_label = 0.0

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True

# ------------------------- Data Augmentation -------------------------
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset = datasets.ImageFolder(root=data_path, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ------------------------- Generator -------------------------
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, input):
        return self.model(input)

# ------------------------- Discriminator -------------------------
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.model(input).view(-1)

# ------------------------- Initialize -------------------------
netG = Generator().to(device)
netD = Discriminator().to(device)

netG.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.ConvTranspose2d, nn.Conv2d, nn.BatchNorm2d)) else None)
netD.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.ConvTranspose2d, nn.Conv2d, nn.BatchNorm2d)) else None)

criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

fixed_noise = torch.randn(8, latent_dim, 1, 1, device=device)

lossD_list = []
lossG_list = []
best_contrast = float('-inf')

# ------------------------- Training Loop -------------------------
print("Starting Training Loop...")
for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(dataloader):
        netD.zero_grad()
        real_images = real_images.to(device)
        b_size = real_images.size(0)

        labels_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)
        output_real = netD(real_images)
        lossD_real = criterion(output_real, labels_real)
        lossD_real.backward()

        noise = torch.randn(b_size, latent_dim, 1, 1, device=device)
        fake_images = netG(noise)
        labels_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)
        output_fake = netD(fake_images.detach())
        lossD_fake = criterion(output_fake, labels_fake)
        lossD_fake.backward()

        optimizerD.step()
        lossD = lossD_real + lossD_fake

        netG.zero_grad()
        labels_gen = torch.full((b_size,), real_label, dtype=torch.float, device=device)
        output_gen = netD(fake_images)
        lossG = criterion(output_gen, labels_gen)
        lossG.backward()
        optimizerG.step()

    lossD_list.append(lossD.item())
    lossG_list.append(lossG.item())

    print(f"[Epoch {epoch+1}/{num_epochs}] Loss_D: {lossD.item():.4f} Loss_G: {lossG.item():.4f}")

    if (epoch + 1) % 20 == 0:
        with torch.no_grad():
            fake = netG(fixed_noise).detach().cpu()
        vutils.save_image(fake, f"generated_epoch_{epoch+1}.png", normalize=True)

        contrast_score = fake.var().item()
        if contrast_score > best_contrast:
            best_contrast = contrast_score
            torch.save(netG.state_dict(), "generator_best.pth")
            print(f"âœ… Best generator saved at epoch {epoch+1} with contrast score {contrast_score:.4f}")

        plt.figure(figsize=(10,5))
        plt.title("Generator and Discriminator Loss During Training")
        plt.plot(lossG_list,label="G")
        plt.plot(lossD_list,label="D")
        plt.xlabel("epochs")
        plt.ylabel("Loss")
        plt.legend()
        plt.show()

# Save final models
torch.save(netG.state_dict(), "generator_final.pth")
torch.save(netD.state_dict(), "discriminator_final.pth")

# ------------------------- Generate Final Best Image -------------------------
best_netG = Generator().to(device)
best_netG.load_state_dict(torch.load("generator_best.pth"))
best_netG.eval()

with torch.no_grad():
    best_fake = best_netG(fixed_noise).detach().cpu()


vutils.save_image(best_fake, "best_generated_image.png", normalize=True)


import matplotlib.pyplot as plt
import matplotlib.image as mpimg

img = mpimg.imread("best_generated_image.png")
plt.figure(figsize=(8, 8))
plt.imshow(img)
plt.axis('off')
plt.title("Best Generated Image")
plt.show()

# View Generated Image
from IPython.display import Image, display

for i in range(10, 601, 10):
    path = f"generated_epoch_{i}.png"
    if os.path.exists(path):
        print(f"ðŸ”¹ Epoch {i}")
        display(Image(filename=path))