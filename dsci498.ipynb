{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "rm -rf ./data/.ipynb_checkpoints\n"
      ],
      "metadata": {
        "id": "0U91TRIGRs9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import requests\n",
        "from duckduckgo_search import DDGS\n",
        "from PIL import Image\n",
        "import glob\n",
        "import shutil\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # ✅ 允许加载损坏图片\n",
        "\n",
        "#设备配置\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#下载图片（每个类别对应一个文件夹）\n",
        "def download_images(person_name, save_dir=\"./data/faces\", num_images=20):\n",
        "    class_dir = os.path.join(save_dir, person_name.replace(\" \", \"_\"))\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.images(person_name, max_results=num_images)\n",
        "\n",
        "    downloaded = 0\n",
        "    for i, result in enumerate(results):\n",
        "        if 'image' not in result or not result['image'].startswith('http'):\n",
        "            continue\n",
        "\n",
        "        image_url = result[\"image\"]\n",
        "        try:\n",
        "            response = requests.get(image_url, stream=True, timeout=5)\n",
        "            if response.status_code == 200 and \"image\" in response.headers.get('content-type', ''):\n",
        "                file_path = os.path.join(class_dir, f\"{i}.jpg\")\n",
        "                with open(file_path, \"wb\") as file:\n",
        "                    for chunk in response.iter_content(1024):\n",
        "                        file.write(chunk)\n",
        "\n",
        "                # ✅ 下载后检查文件是否损坏\n",
        "                if os.path.getsize(file_path) < 10240:  # 小于 10KB 说明可能损坏\n",
        "                    print(f\"⚠️ 删除损坏的图片: {file_path}\")\n",
        "                    os.remove(file_path)\n",
        "                else:\n",
        "                    downloaded += 1\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if downloaded == 0:\n",
        "        raise FileNotFoundError(\"No images downloaded. Check your network or DuckDuckGo settings.\")\n",
        "\n",
        "    print(f\"✅ 下载 {downloaded} 张图片到 {class_dir}\")\n",
        "\n",
        "\n",
        "#确保 `ImageFolder` 的数据结构正确\n",
        "def fix_dataset_structure(data_root=\"./data/faces\"):\n",
        "    \"\"\"\n",
        "    - 确保 `data_root` 目录下至少有一个类别文件夹。\n",
        "    - 如果 `default/` 目录里直接存放图片，移动到 `default/images/` 作为类别。\n",
        "    - 删除 `.ipynb_checkpoints/` 目录。\n",
        "    \"\"\"\n",
        "    # 删除 `.ipynb_checkpoints/`\n",
        "    checkpoints = os.path.join(data_root, \".ipynb_checkpoints\")\n",
        "    if os.path.exists(checkpoints):\n",
        "        shutil.rmtree(checkpoints)\n",
        "        print(\"删除 .ipynb_checkpoints\")\n",
        "\n",
        "    valid_folders = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d)) and not d.startswith('.')]\n",
        "\n",
        "    # 如果 `data_root` 下没有类别文件夹\n",
        "    if len(valid_folders) == 0:\n",
        "        print(\"⚠️ 没有类别文件夹，检查是否有图片需要移动...\")\n",
        "        default_path = os.path.join(data_root, \"default\")\n",
        "        os.makedirs(default_path, exist_ok=True)\n",
        "\n",
        "        # 识别 `data_root` 里的所有图片\n",
        "        for file in os.listdir(data_root):\n",
        "            if file.endswith((\"jpg\", \"jpeg\", \"png\")):\n",
        "                shutil.move(os.path.join(data_root, file), os.path.join(default_path, file))\n",
        "\n",
        "        valid_folders.append(\"default\")\n",
        "\n",
        "    print(f\"数据集类别文件夹: {valid_folders}\")\n",
        "\n",
        "#预处理图片\n",
        "def preprocess_images(image_dir):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    files = glob.glob(image_dir + \"/*.*\")  # 处理所有格式\n",
        "    for file in files:\n",
        "        try:\n",
        "            with Image.open(file) as img:\n",
        "                img = img.convert(\"RGB\")  # 转换为 RGB 模式\n",
        "                img_transformed = transform(img)  # 变换为 Tensor\n",
        "\n",
        "                # 重新转换回 PIL 再保存\n",
        "                img_transformed = transforms.ToPILImage()(img_transformed)\n",
        "                img_transformed.save(file.replace(\".jpg\", \"_processed.jpg\"))\n",
        "\n",
        "        except (OSError, IOError):\n",
        "            print(f\"❌ 跳过损坏的图片: {file}\")\n",
        "            os.remove(file)  #删除损坏的图片\n",
        "\n",
        "    print(\"✅ All images preprocessed!\")\n",
        "\n",
        "#训练数据集加载\n",
        "data_root = \"./data/faces\"\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def is_valid_file(path):\n",
        "    return path.lower().endswith(('jpg', 'jpeg', 'png'))\n",
        "\n",
        "# 修正数据结构\n",
        "fix_dataset_structure(data_root)\n",
        "\n",
        "# 重新检查并加载数据\n",
        "dataset = dsets.ImageFolder(root=data_root, transform=transform, is_valid_file=is_valid_file)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "print(\"✅ 数据集加载成功！类别:\", dataset.classes)\n",
        "\n",
        "#定义 DCGAN 生成器 & 判别器\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# 7️⃣ 训练 DCGAN\n",
        "def train_dcgan(epochs=100):\n",
        "    netG = Generator(100, 64, 3).to(device)\n",
        "    netD = Discriminator(3, 64).to(device)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (data, _) in enumerate(dataloader):\n",
        "            real_data = data.to(device)\n",
        "            noise = torch.randn(real_data.size(0), 100, 1, 1, device=device)\n",
        "            fake_data = netG(noise)\n",
        "\n",
        "        print(f\"Epoch [{epoch}/{epochs}] completed.\")\n",
        "\n",
        "# 示例：下载、预处理并训练\n",
        "person_name = \"Trump\"\n",
        "download_images(person_name, num_images=50)\n",
        "train_dcgan(epochs=50)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I58pylMefihu",
        "outputId": "29a44237-db6d-43e8-ef44-7ab290f305eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 数据集类别文件夹: ['default', 'Elon_Musk']\n",
            "✅ 数据集加载成功！类别: ['Elon_Musk', 'default']\n",
            "✅ 下载 49 张图片到 ./data/faces/Trump\n",
            "Epoch [0/50] completed.\n",
            "Epoch [1/50] completed.\n",
            "Epoch [2/50] completed.\n",
            "Epoch [3/50] completed.\n",
            "Epoch [4/50] completed.\n",
            "Epoch [5/50] completed.\n",
            "Epoch [6/50] completed.\n",
            "Epoch [7/50] completed.\n",
            "Epoch [8/50] completed.\n",
            "Epoch [9/50] completed.\n",
            "Epoch [10/50] completed.\n",
            "Epoch [11/50] completed.\n",
            "Epoch [12/50] completed.\n",
            "Epoch [13/50] completed.\n",
            "Epoch [14/50] completed.\n",
            "Epoch [15/50] completed.\n",
            "Epoch [16/50] completed.\n",
            "Epoch [17/50] completed.\n",
            "Epoch [18/50] completed.\n",
            "Epoch [19/50] completed.\n",
            "Epoch [20/50] completed.\n",
            "Epoch [21/50] completed.\n",
            "Epoch [22/50] completed.\n",
            "Epoch [23/50] completed.\n",
            "Epoch [24/50] completed.\n",
            "Epoch [25/50] completed.\n",
            "Epoch [26/50] completed.\n",
            "Epoch [27/50] completed.\n",
            "Epoch [28/50] completed.\n",
            "Epoch [29/50] completed.\n",
            "Epoch [30/50] completed.\n",
            "Epoch [31/50] completed.\n",
            "Epoch [32/50] completed.\n",
            "Epoch [33/50] completed.\n",
            "Epoch [34/50] completed.\n",
            "Epoch [35/50] completed.\n",
            "Epoch [36/50] completed.\n",
            "Epoch [37/50] completed.\n",
            "Epoch [38/50] completed.\n",
            "Epoch [39/50] completed.\n",
            "Epoch [40/50] completed.\n",
            "Epoch [41/50] completed.\n",
            "Epoch [42/50] completed.\n",
            "Epoch [43/50] completed.\n",
            "Epoch [44/50] completed.\n",
            "Epoch [45/50] completed.\n",
            "Epoch [46/50] completed.\n",
            "Epoch [47/50] completed.\n",
            "Epoch [48/50] completed.\n",
            "Epoch [49/50] completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(netG.state_dict(), \"generator1.pth\")  # 训练时保存\n"
      ],
      "metadata": {
        "id": "5Qt548EdoTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# 载入训练好的模型\n",
        "netG = Generator(100, 64, 3).to(device)\n",
        "netG.load_state_dict(torch.load(\"generator1.pth\"))  # 假设你保存了模型\n",
        "\n",
        "# 生成假人脸\n",
        "noise = torch.randn(64, 100, 1, 1, device=device)  # 64 个噪声样本\n",
        "fake_images = netG(noise).detach().cpu()\n",
        "\n",
        "# 保存或显示\n",
        "vutils.save_image(fake_images, \"generated_faces2.png\", normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J8mnagMnvSz",
        "outputId": "7cd1c757-f62a-49a8-dced-5a376bdee687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-049377bcc984>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  netG.load_state_dict(torch.load(\"generator1.pth\"))  # 假设你保存了模型\n"
          ]
        }
      ]
    }
  ]
}